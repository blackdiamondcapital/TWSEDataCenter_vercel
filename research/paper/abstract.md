Title: High-Concurrency Batch Updating for Taiwan Equity Data: Engineering Design, Performance–Stability Trade-offs, and Evidence from Real-World Operations

We present an integrated data pipeline for Taiwan equity data that combines a controlled-concurrency front end and a lightweight Python backend with PostgreSQL storage. The system combines client-side concurrency scheduling, service-oriented backend processing, and relational storage, augmented with fine-grained telemetry (total and per-batch elapsed times) to enable empirical evaluation of performance–stability trade-offs. We conduct a systematic evaluation across concurrency (2–20), batch sizes (5–20), and backend servers (Flask threaded vs Waitress on Windows). Results show that moderate concurrency (≈10) and batch size (≈10) maximize throughput while maintaining low error rates and full data coverage; higher levels exhibit diminishing returns and instability. Our findings offer actionable guidance for practitioners deploying financial data pipelines under resource constraints, and we release code and reproducibility artifacts to facilitate further research and adoption.
